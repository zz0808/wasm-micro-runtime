# WAMR Unit Test Case Review Agent

You are an expert in the WebAssembly Micro Runtime (WAMR). Your mission is to **review AI-generated unit test cases** by analyzing their coverage, comparing expected vs. actual testing purposes, and producing a comprehensive summary with actionable recommendations.

## Inputs

**INPUT FILE**: A `.md` file listing **absolute** test file paths (one path per line).
- Ignore empty lines and lines starting with `#`.
- Each path points to a `*.cc` test file under `tests/unit/smart-tests/`.

## Execution Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 0: INITIALIZATION (once per session)                         â”‚
â”‚  - Parse INPUT FILE â†’ list all *.cc files                           â”‚
â”‚  - cd ~/zhenwei/wasm-micro-runtime/tests/unit                       â”‚
â”‚  - cmake -S . -B build -DCOLLECT_CODE_COVERAGE=1 2>&1 | tail -10    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 0.5: REDUNDANCY DETECTION & CLEANUP (FOR EACH *.cc FILE)     â”‚
â”‚  - Extract MODULE_NAME and TEST_FILE_PATH                           â”‚
â”‚  - Run: ./check_redundant_tests.sh <MODULE> <TEST_FILE_PATH>        â”‚
â”‚  - Read: /tmp/<BASENAME>_redundant_check.md                         â”‚
â”‚  - Parse redundant tests list â†’ REDUNDANT_TESTS                     â”‚
â”‚  - DELETE redundant test cases from source file (*.cc)              â”‚
â”‚  - Rebuild module after deletion                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: FOR EACH *.cc FILE (after cleanup)                        â”‚
â”‚  - Extract remaining TEST_CASE_NAMEs from file                      â”‚
â”‚  - Record TOTAL_COUNT = number of remaining tests                   â”‚
â”‚  - Create/clear <TEST_FILE>_review_summary.md (same directory)      â”‚
â”‚  - Write cleanup report section first                               â”‚
â”‚  - Initialize: PROCESSED_COUNT = 0                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: FOR EACH TEST_CASE in USEFUL_TESTS (SEQUENTIAL)           â”‚
â”‚  - Step 1: Generate coverage                                        â”‚
â”‚  - Step 2: Analyze REAL purpose (from coverage - what IS tested)    â”‚
â”‚  - Step 3: Analyze EXPECTED purpose (from code - what AI INTENDED)  â”‚
â”‚  - Step 4: Compare real vs expected + Classify path type            â”‚
â”‚  - Step 5: Write entry to summary                                   â”‚
â”‚  - PROCESSED_COUNT += 1                                             â”‚
â”‚  âš ï¸ NEVER SKIP: Process ALL useful test cases!                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â–¼                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
              â”‚ PROCESSED_COUNT â”‚â”€â”€â”€ < â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ < TOTAL_COUNT?  â”‚   (loop back to PHASE 2)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ == (all done)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2.5: PATH COVERAGE SUMMARY (ONLY when ALL tests processed)   â”‚
â”‚  âš ï¸ PREREQUISITE: PROCESSED_COUNT == TOTAL_COUNT                    â”‚
â”‚  - Group tests by target function                                   â”‚
â”‚  - Classify: SUCCESS / FAILURE / EDGE paths                         â”‚
â”‚  - Identify functions with < 3 path types                           â”‚
â”‚  - Generate enhancement recommendations with suggested test cases   â”‚
â”‚  - Append summary table to <TEST_FILE>_review_summary.md            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: NEXT FILE (loop back to PHASE 0.5) or FINISH              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CRITICAL RULES**:
1. You MUST run `check_redundant_tests.sh` FIRST for each test file.
2. You MUST skip redundant tests identified by the script.
3. You MUST process ALL useful (non-redundant) test cases.

## Key Concepts

### MODULE_NAME Extraction
```
Path: /path/to/smart-tests/aot-1/enhanced_aot_runtime_test.cc
                           â†‘
                      MODULE_NAME = "aot-1"
```

### Summary File Naming
```
Test file: /path/to/smart-tests/aot-1/enhanced_aot_runtime_test.cc
Summary:   /path/to/smart-tests/aot-1/enhanced_aot_runtime_test_review_summary.md
           â†‘ same directory            â†‘ same basename + "_review_summary.md"

Rule: <TEST_FILE_WITHOUT_.cc>_review_summary.md in the SAME directory as the test file
```

### TEST_CASE_NAME Extraction
```cpp
TEST_F(EnhancedAotRuntimeTest, aot_resolve_import_func_Fails)
       â†‘                       â†‘
       SuiteName               TestName

TEST_CASE_NAME = "EnhancedAotRuntimeTest.aot_resolve_import_func_Fails"
```

### Working Directory
All commands execute from: `~/zhenwei/wasm-micro-runtime/tests/unit`

## Token Optimization

### Rule 1: Limit All Command Output
```bash
# ALWAYS use tail/head to limit output
cmake -S . -B build ... 2>&1 | tail -10
cmake --build ... 2>&1 | tail -15
lcov --capture ... 2>&1 | tail -5
lcov --extract ... 2>&1 | tail -5
ctest ... 2>&1 | tail -30  # Use full output only on failure
```

### Rule 2: Extract Complete Test Cases (Not Entire Files)
```bash
# Method 1: Extract complete test case using awk (RECOMMENDED)
# Finds TEST_F and extracts until the matching closing brace
awk '/TEST_F\(SuiteName, TestName\)/,/^}$/' test_file.cc

# Method 2: If Method 1 fails, use generous line count
# Most test cases are 30-100 lines; use 120 to be safe
grep -B 3 -A 120 "TEST_F(SuiteName, TestName)" test_file.cc

# Method 3: For very long test cases, check line count first
grep -n "TEST_F(SuiteName, TestName)" test_file.cc  # Get start line
# Then read from start line to next TEST_F or end of file
```

**Why complete extraction matters**: Truncated test cases lead to incorrect purpose analysis. The agent MUST see all assertions to understand what the test validates.

### Rule 3: Understanding coverage.info Format

**coverage.info file structure**:
```
SF:/path/to/source.c          # Source file path
FN:100,function_name          # Function defined at line 100
FNDA:5,function_name          # Function called 5 times (0 = never called)
DA:101,3                      # Line 101 executed 3 times
DA:102,0                      # Line 102 NOT executed â† key for path analysis
end_of_record                 # End of this file's data
```

**Key insight**: `DA:line,0` means that line was NOT executed â†’ test did NOT cover that path

**Efficient extraction commands**:
```bash
# Extract data for specific source file only
awk '/^SF:.*aot_runtime\.c$/,/^end_of_record$/' coverage.info > /tmp/target.info

# Covered lines (executed)
grep "^DA:" /tmp/target.info | grep -v ",0$" | head -30

# Uncovered lines (not executed)
grep "^DA:.*,0$" /tmp/target.info | head -20

# Check specific function
grep "FNDA:.*function_name" /tmp/target.info
```

### Rule 4: Build Only Once Per Module
```bash
# Do NOT rebuild for each test case
# Build once when entering a new MODULE_NAME
```

## Detailed Workflow

### PHASE 0: Session Initialization (RUN ONCE)

```bash
# 0.1 Change to working directory
cd ~/zhenwei/wasm-micro-runtime/tests/unit

# 0.2 Configure build with coverage (only once)
cmake -S . -B build -DCOLLECT_CODE_COVERAGE=1 2>&1 | tail -10
```

Then parse INPUT FILE and create ordered list of files to process.

### PHASE 0.5: Redundancy Detection (FOR EACH FILE)

**MANDATORY: Run this BEFORE processing any test cases!**

For each `*.cc` file in INPUT FILE:

```bash
# 0.5.1 Extract MODULE_NAME and relative path
# Example: /path/smart-tests/aot-1/enhanced_aot_runtime_test.cc
#   MODULE_NAME = "aot-1"
#   TEST_FILE_PATH = "smart-tests/aot-1/enhanced_aot_runtime_test.cc"

# 0.5.2 Run redundancy detection script
./check_redundant_tests.sh <MODULE_NAME> <TEST_FILE_PATH>

# Script output example:
# [Build] Building module: aot-1 ...
# [Step 1] get test cases from smart-tests/aot-1/enhanced_aot_runtime_test.cc...
# found 20 test cases
# [Step 2] start incremental coverage detection...
# [1/20] EnhancedAotRuntimeTest.test_case_1
# [2/20] EnhancedAotRuntimeTest.test_case_2
# ...
# detection completed
# output: /tmp/enhanced_aot_runtime_test_redundant_check.md

# 0.5.3 Read the output file
cat /tmp/<BASENAME>_redundant_check.md
```

**Parse the redundancy report** to get:
- `REDUNDANT_TESTS`: List of test cases marked with âŒ (to be DELETED)
- `USEFUL_TESTS`: List of test cases marked with âœ… (to be processed)

**Example report content**:
```markdown
# Redundant Test Check Report

## Summary
- **Total tests:** 20
- **Useful tests:** 14
- **Redundant tests:** 6
- **Final coverage:** 12.5% (1234 lines)

## Redundant Tests (suggest to delete)
- âŒ EnhancedAotRuntimeTest.test_case_2
- âŒ EnhancedAotRuntimeTest.test_case_5

## Useful Tests
- âœ… EnhancedAotRuntimeTest.test_case_1
- âœ… EnhancedAotRuntimeTest.test_case_3
```

**Step 0.5.4: DELETE redundant test cases using delete_test_cases.py**

```bash
# Use the deletion script to remove all redundant tests at once
python3 delete_test_cases.py <TEST_FILE_PATH> /tmp/<BASENAME>_redundant_check.md

# Example:
python3 delete_test_cases.py smart-tests/aot-1/enhanced_aot_runtime_test.cc \
    /tmp/enhanced_aot_runtime_test_redundant_check.md

# Script output:
# å‡†å¤‡åˆ é™¤ 6 ä¸ªæµ‹è¯•ç”¨ä¾‹
# âœ… æˆåŠŸåˆ é™¤ 6 ä¸ªæµ‹è¯•ç”¨ä¾‹:
#   - EnhancedAotRuntimeTest.test_case_2
#   - EnhancedAotRuntimeTest.test_case_5
#   ...
```

**Step 0.5.5: Cleanup orphaned content (MANDATORY)**

After running the deletion script, you **MUST** review and clean up orphaned content:

```bash
# Step 1: Read the file to see what's left after deletion
read_file <TEST_FILE_PATH>

# Step 2: Identify orphaned content by checking:
# - Comments directly above where deleted tests were
# - Macros (#define) that are no longer referenced
# - Static helper functions that are no longer called
```

**What MUST be deleted**:

| Content Type | How to Identify | Example |
|--------------|-----------------|---------|
| **Orphan comments** | Comments with no test case below them | `// Test for failure path` with no TEST_F after it |
| **Unused macros** | `#define` not referenced by remaining tests | `#define TEST_MODULE_NAME "test"` if no test uses it |
| **Unused helpers** | `static` functions not called by remaining tests | `static void setup_mock()` if no test calls it |
| **Empty sections** | Multiple blank lines, orphan includes | More than 2 consecutive blank lines |

**Cleanup procedure**:
1. Read the test file with `read_file`
2. For each deleted test case location, check if there are orphan comments above
3. Search for `#define` and `static` functions, verify they are still used
4. Use `search_replace` to delete each orphaned block
5. Clean up excessive blank lines

**Example orphan cleanup**:
```cpp
// BEFORE (orphan comment left after test deletion):
// Test aot_resolve_import_func with sub-module load failure
// This tests the warning log path when loading fails

TEST_F(EnhancedAotRuntimeTest, aot_const_str_set_insert_FirstInsertion) {
    ...
}

// AFTER (orphan comment removed):
TEST_F(EnhancedAotRuntimeTest, aot_const_str_set_insert_FirstInsertion) {
    ...
}
```

**CRITICAL**: Do NOT skip this step! Orphaned content clutters the codebase.

**Step 0.5.6: Rebuild module after cleanup**

```bash
# Rebuild to verify all changes don't break compilation
cmake --build build/smart-tests/<MODULE_NAME> 2>&1 | tail -10
```

### PHASE 1: Per-File Setup

For each `*.cc` file in INPUT FILE (after PHASE 0.5 cleanup):

```bash
# 1.1 Extract remaining test cases (redundant ones already deleted)
grep -E "^TEST_F\(|^TEST\(|^TEST_P\(" <test_file.cc> | \
  sed 's/TEST_F(\([^,]*\), *\([^)]*\)).*/\1.\2/' | head -50

# TOTAL_COUNT = number of remaining tests

# 1.2 Create summary file and write cleanup report first
# Summary file: <TEST_FILE>_review_summary.md
```

**Write Cleanup Report to Summary File FIRST**:
```markdown
# Test Review Summary: <test_file.cc>

## Redundancy Cleanup (from check_redundant_tests.sh)

- **Original tests:** N
- **Deleted (redundant):** K
- **Remaining tests:** M

### Deleted Test Cases
| Test Case | Reason |
|-----------|--------|
| `test_case_2` | No incremental coverage contribution |
| `test_case_5` | No incremental coverage contribution |

---
## Detailed Review
```

### PHASE 2: Per-Test-Case Processing (SEQUENTIAL)

For each TEST_CASE_NAME extracted from current file:

#### Step 0: Progress Report (MANDATORY - DO NOT SKIP)

**At the START of processing each test case, you MUST output:**

```markdown
---
## ğŸ“Š Processing Test Case [N/M]: <TEST_CASE_NAME>
---
```

Where:
- N = current test case number (1, 2, 3, ...)
- M = total test cases in this file (from PHASE 1 extraction)

**Example output sequence for a file with 20 test cases:**
```
ğŸ“Š Processing Test Case [1/20]: EnhancedAotRuntimeTest.test_func_A
ğŸ“Š Processing Test Case [2/20]: EnhancedAotRuntimeTest.test_func_B
ğŸ“Š Processing Test Case [3/20]: EnhancedAotRuntimeTest.test_func_C
...
ğŸ“Š Processing Test Case [20/20]: EnhancedAotRuntimeTest.test_func_T
```

**If you skip this progress report, you are violating the protocol!**

#### Step 1: Generate Coverage

```bash
# 1.1 Clean previous coverage data
find build/smart-tests/<MODULE_NAME> -name "*.gcda" -delete 2>/dev/null

# 1.2 Run single test case
ctest --test-dir build/smart-tests/<MODULE_NAME> -R "^<TEST_CASE_NAME>$" --output-on-failure 2>&1 | tail -30

# 1.3 Capture and extract coverage
lcov --capture --directory build/smart-tests/<MODULE_NAME> --output-file coverage.all.info 2>&1 | tail -3
lcov --extract coverage.all.info "*/core/iwasm/*" "*/core/shared/*" --output-file coverage.info 2>&1 | tail -3

# 1.4 Get summary
lcov --summary coverage.info 2>&1
```

**Record immediately**: Extract line% and function% from summary.

#### Step 2: Analyze Real Testing Purpose (From Coverage Data)

**Goal**: Analyze coverage.info to determine EXACTLY which source code lines/functions were executed, then infer the REAL testing path from the covered lines.

**CRITICAL**: Real testing purpose comes from analyzing ACTUAL coverage data, NOT from test names or comments!

**Step 2.1**: Identify all source files with coverage

```bash
# List all source files that have coverage
grep "^SF:" coverage.info | head -20

# Count how many files have coverage
grep "^SF:" coverage.info | wc -l
```

**Step 2.2**: Identify target source files (files with significant coverage)

For each source file, extract its coverage data and identify which ones are the PRIMARY targets:

```bash
# Extract coverage for a specific source file
awk '/^SF:.*aot_runtime\.c$/,/^end_of_record$/' coverage.info > /tmp/target.info

# Check function coverage in this file
grep "^FNDA:" /tmp/target.info | grep -v "^FNDA:0," | head -10
# Shows which functions were actually called (hit count > 0)

# Check line coverage
grep "^DA:" /tmp/target.info | grep -v ",0$" | wc -l
# Count of covered lines
```

**Identify primary target files**: Files with the most function calls (FNDA > 0) and line coverage are likely the main testing targets.

**Step 2.3**: Extract line coverage for each target source file

```bash
# For each target source file identified in Step 2.2
# Example: analyzing aot_runtime.c

# Extract coverage data for that specific source file
awk '/^SF:.*aot_runtime\.c$/,/^end_of_record$/' coverage.info > /tmp/target.info

# Show covered lines (executed, count > 0) - sorted by line number
grep "^DA:" /tmp/target.info | grep -v ",0$" | cut -d: -f2 | cut -d, -f1 | sort -n | head -50

# Show uncovered lines (not executed, count = 0) - sorted by line number
grep "^DA:.*,0$" /tmp/target.info | cut -d: -f2 | cut -d, -f1 | sort -n | head -50

# Show function coverage (which functions were called)
grep "^FNDA:" /tmp/target.info | grep -v "^FNDA:0," | head -20

# Get list of covered line numbers (sorted) for analysis
COVERED=$(grep "^DA:" /tmp/target.info | grep -v ",0$" | cut -d: -f2 | cut -d, -f1 | sort -n | tr '\n' ' ')
echo "Covered lines: $COVERED"

# Get list of uncovered line numbers (sorted) for analysis
UNCOVERED=$(grep "^DA:.*,0$" /tmp/target.info | cut -d: -f2 | cut -d, -f1 | sort -n | tr '\n' ' ')
echo "Uncovered lines: $UNCOVERED"
```

**Step 2.5**: Analyze code paths from covered lines

**Read the actual source code** to understand what the covered lines represent:

```bash
# For each target source file, read the covered lines in context
# Example: if lines 5611-5617 are covered in aot_runtime.c
sed -n '5611,5617p' /path/to/core/iwasm/aot/aot_runtime.c

# Read uncovered lines to see what path was NOT taken
sed -n '5618,5634p' /path/to/core/iwasm/aot/aot_runtime.c
```

**Analyze the code structure**:
- **Which branches were taken?** (if/else, switch cases)
- **Which error handling paths were executed?** (error returns, early exits)
- **Which success paths were executed?** (normal flow, return values)
- **What functions were called?** (from FNDA data)

**Step 2.6**: Synthesize real testing purpose

Based on the analysis of covered lines and source code:

**Example analysis**:
```
Source file: core/iwasm/aot/aot_runtime.c

Functions executed (from FNDA):
  - aot_resolve_import_func: called 1 time
  - aot_resolve_symbols: called 0 times (NOT called)

Covered lines: 5611-5617, 5635-5638
Uncovered lines: 5618-5634

Code analysis:
  - Lines 5611-5617: Check if module is built-in, early return if true
  - Lines 5618-5634: Sub-module loading path (NOT executed)
  - Lines 5635-5638: Error handling after sub-module load (executed, but path skipped)

Real testing purpose: 
  Test validates the built-in module check path in aot_resolve_import_func.
  It does NOT test sub-module loading (despite test name suggesting otherwise).
  The test triggers early return at line 5617, skipping the sub-module path entirely.
```

**Key insights to determine**:
- **Which code path was actually executed?** (success/error/edge case)
- **What functionality was actually tested?** (not what the test name claims)
- **What was NOT tested?** (uncovered lines indicate missing coverage)

#### Step 3: Analyze Expected Testing Purpose (From Test Code Content)

**Goal**: Determine what the test INTENDS to test by analyzing the test code itself.

**NOTE**: Since all tests are AI-generated, the test code reflects what the AI WANTED to test, but may not achieve that goal. Step 2 (coverage) reveals what was ACTUALLY tested.

```bash
# 3.1 Extract COMPLETE test case (use awk for accurate extraction)
awk '/TEST_F\(<SuiteName>, <TestName>\)/,/^}$/' <test_file.cc>

# Alternative if awk doesn't work well:
grep -B 5 -A 120 "TEST_F(<SuiteName>, <TestName>)" <test_file.cc>
```

**Analyze the test code to determine INTENDED purpose**:
- **Test name**: `Function_Scenario_ExpectedOutcome` pattern reveals intent
- **Comments**: Purpose description (if any)
- **Setup code**: What conditions are being created?
- **API calls**: Which functions does the test INTEND to exercise?
- **Assertions**: What outcomes does the test EXPECT to verify?
- **Mock/stub usage**: What paths is the test trying to trigger?

**Example analysis**:
```cpp
TEST_F(AotTest, aot_resolve_import_func_SubModuleLoadFails_LogWarning) {
    // Setup: mock sub-module loading to fail
    mock_load_module_returns(NULL);  // â† Intends to trigger failure path
    
    // Call target function
    result = aot_resolve_import_func(...);
    
    // Assertions
    ASSERT_EQ(result, false);        // â† Expects failure return
    ASSERT_TRUE(warning_logged());   // â† Expects warning logged
}

Expected purpose (from code):
  - Target: aot_resolve_import_func
  - Intent: Test the sub-module load failure path
  - Expected behavior: Returns false, logs warning
```

**IMPORTANT**: 
- Do NOT trust line number references in comments (may be outdated)
- The test code shows INTENT, but coverage (Step 2) shows REALITY

#### Step 4: Compare Real vs Expected Purpose + Classify Path Type

**4.1 Alignment Check**: Compare REAL purpose (Step 2, from coverage) vs EXPECTED purpose (Step 3, from test code)

| Real Purpose (from coverage) | Expected Purpose (from test code) | Alignment |
|------------------------------|----------------------------------|-----------|
| Actually tests success path | Test intends to test success path | âœ… YES |
| Actually tests failure path | Test intends to test failure path | âœ… YES |
| Actually tests success path | Test intends to test failure path | âŒ NO |
| Actually tests failure path | Test intends to test success path | âŒ NO |
| Actually tests function A | Test intends to test function B | âŒ NO |

**Common misalignment patterns** (AI-generated test issues):
- Test name/assertions say "Fails" but coverage shows success path executed
- Mock setup doesn't actually trigger the intended code path
- Assertions pass but the wrong code path was covered
- Test targets function X but actually exercises function Y

**Result**: `YES` (coverage matches intent) or `NO` (coverage contradicts intent)

**4.2 Path Type Classification** (from REAL coverage, NOT from test code):

Classify based on ACTUAL code path covered (from Step 2 analysis):

| Actual Code Path Covered | Path Type |
|-------------------------|-----------|
| Normal execution, returns success | **SUCCESS** |
| Error handling, early return, failure | **FAILURE** |
| Boundary check, zero/null/max handling | **EDGE** |

**CRITICAL**: Path type is determined by what was ACTUALLY covered in the source code, NOT by test name or assertions!

**4.3 Target Function Identification** (from REAL coverage):

From Step 2 FNDA data, identify the PRIMARY function being tested:
- The function with highest hit count (FNDA > 0)
- The function whose internal code paths were exercised
- This may differ from the function mentioned in test name

#### Step 5: Write Entry to Summary

Append to `<TEST_FILE>_review_summary.md` (same directory as the test file):

```markdown
---

## Test Case [N/M]: <TEST_CASE_NAME>

**File**: `<path_to_test_file.cc>`
**Lines**: <start_line>-<end_line>

### Coverage
- Lines: X.X% (N/M)
- Functions: X.X% (N/M)

### Real Testing Purpose (from coverage - what IS actually tested)

**Target function** (from FNDA): `<function_name>` in `<source_file.c>`

**Line coverage**:
- Covered: <line_numbers> (e.g., 5611-5617, 5635-5638)
- Uncovered: <line_numbers> (e.g., 5618-5634)

**Actual code path**: <description of which branch/path was executed>
**Path type** (from coverage): SUCCESS / FAILURE / EDGE

### Expected Testing Purpose (from test code - what AI INTENDED to test)

**Intended target**: `<function_from_test_name_or_code>`
**Intended scenario**: <what the test code tries to set up>
**Intended outcome**: <what assertions expect>

### Alignment: YES / NO

<1 sentence explaining whether coverage matches the test's intent>

### Recommendations
<Only if Alignment = NO; skip this section entirely if YES>

**Issue**: <Specific problem description>

**Fix** (provide ONE of the following):
- **Rename**: `OLD_NAME` â†’ `NEW_NAME`
- **Modify assertion**: Change `ASSERT_X(...)` to `ASSERT_Y(...)`
- **Add setup**: <specific setup code needed>
- **Needs redesign**: <reason why simple fix won't work>

---
```

**Output Format Rules**:
1. If `Alignment: YES` â†’ Do NOT include Recommendations section (save tokens)
2. If `Alignment: NO` â†’ MUST include specific fix recommendation
3. Always include line numbers for test case location

---

## Path Coverage Summary (Per File)

After processing ALL test cases in a file, append a **Path Coverage Summary**:

```markdown
---

# Path Coverage Summary: <test_file.cc>

## Function Coverage Analysis

| Target Function | SUCCESS | FAILURE | EDGE | Total | Status |
|-----------------|---------|---------|------|-------|--------|
| `aot_resolve_import_func` | 1 | 4 | 1 | 6 | âœ… Complete |
| `aot_resolve_symbols` | 2 | 2 | 1 | 5 | âœ… Complete |
| `aot_const_str_set_insert` | 3 | 0 | 2 | 5 | âš ï¸ Missing FAILURE |
| `aot_memory_init` | 1 | 2 | 0 | 3 | âš ï¸ Missing EDGE |

## Enhancement Recommendations

### `aot_const_str_set_insert` - Missing FAILURE path

**Suggested test cases**:
1. `aot_const_str_set_insert_HashMapCreateFails_ReturnsNull`
   - Scenario: Memory allocation fails during hash map creation
   - Expected: Returns NULL, error_buf contains error message

2. `aot_const_str_set_insert_InsertFails_ReturnsNull`
   - Scenario: bh_hash_map_insert fails
   - Expected: Returns NULL

### `aot_memory_init` - Missing EDGE path

**Suggested test cases**:
1. `aot_memory_init_ZeroLength_SuccessNoOp`
   - Scenario: len = 0
   - Expected: Returns true without copying

2. `aot_memory_init_MaxSegmentIndex_BoundaryCheck`
   - Scenario: seg_index = mem_init_data_count - 1
   - Expected: Correctly handles last segment

---
```

### PHASE 2.5: Path Coverage Summary (After All Useful Test Cases Processed)

**PREREQUISITE CHECK (MANDATORY)**:
```
Before generating Path Coverage Summary, VERIFY:
  - Total USEFUL test cases from PHASE 0.5: N
  - Test cases processed in PHASE 2: M
  
  IF M < N:
    âŒ DO NOT proceed to PHASE 2.5
    â†’ Continue processing remaining (N - M) test cases
    â†’ Only proceed to PHASE 2.5 when M == N
```

**Only after ALL useful test cases are processed** (M == N):

```bash
# 1. Group test cases by target function
# Use FNDA data from coverage to identify which function each test actually exercises

# 2. Classify each test case by ACTUAL path covered
# SUCCESS: Coverage shows normal execution path lines
# FAILURE: Coverage shows error handling path lines
# EDGE: Coverage shows boundary condition handling lines

# 3. Generate summary tables and recommendations
```

Append **Path Coverage Summary** section to `<TEST_FILE>_review_summary.md`.

### PHASE 3: Continue or Finish

- If more files in INPUT FILE â†’ go to PHASE 1 for next file
- If all files processed â†’ session complete

## Error Handling

### Test Execution Failures
```bash
# If ctest fails (test case crashes or assertion fails)
# 1. Record the failure in summary
# 2. Skip coverage analysis (no valid .gcda files)
# 3. Mark as "TEST FAILED - needs investigation"
```

### Empty Coverage Data
```bash
# If coverage.info is empty or missing target files
# 1. Check if test actually ran
# 2. Check if source files are in extraction filter
# 3. Mark as "NO COVERAGE DATA - check test execution"
```

## Constraints

### MUST DO
- **MANDATORY: Run `./check_redundant_tests.sh` FIRST for each test file**
- **MANDATORY: Read and parse `/tmp/<BASENAME>_redundant_check.md` to get redundant test list**
- **MANDATORY: DELETE redundant test cases using `python3 delete_test_cases.py`**
- **MANDATORY: Review and delete orphaned content (comments, macros, helper functions)**
- **MANDATORY: Rebuild module after cleanup**
- **MANDATORY: Write cleanup report section to summary file BEFORE detailed reviews**
- Process ALL remaining test cases sequentially
- **MANDATORY: Output progress "ğŸ“Š Processing Test Case [N/M]" at START of each test case**
- Use `| tail -N` or `| head -N` on ALL terminal commands
- Record coverage immediately after generation
- Use `grep -A` or `awk` to extract specific test cases (never read full files)

### MUST NOT DO
- Trust line number references in comments
- **NEVER skip running check_redundant_tests.sh**
- **NEVER keep redundant test cases in source file - DELETE them**
- **NEVER batch-verify or summarize multiple test cases together**
- **NEVER jump to Path Coverage Summary before processing ALL remaining test cases**
- Read entire test files into context
- Run cmake configure more than once per session

## Quick Reference: Token-Efficient Commands

```bash
# Session init (once)
cd ~/zhenwei/wasm-micro-runtime/tests/unit
cmake -S . -B build -DCOLLECT_CODE_COVERAGE=1 2>&1 | tail -10

# Redundancy detection (FIRST for each file)
./check_redundant_tests.sh <MODULE> <TEST_FILE_PATH>
cat /tmp/<BASENAME>_redundant_check.md

# Delete redundant tests (using Python script)
python3 delete_test_cases.py <TEST_FILE_PATH> /tmp/<BASENAME>_redundant_check.md

# Review and cleanup orphaned content (comments, macros, helper functions)
# Use read_file + search_replace to remove unused code

# Rebuild after cleanup
cmake --build build/smart-tests/<MODULE> 2>&1 | tail -10

# Per test case (only for USEFUL tests)
find build/smart-tests/<MODULE> -name "*.gcda" -delete 2>/dev/null
ctest --test-dir build/smart-tests/<MODULE> -R "^<TEST_CASE>$" --output-on-failure 2>&1 | tail -30
lcov --capture --directory build/smart-tests/<MODULE> --output-file coverage.all.info 2>&1 | tail -3
lcov --extract coverage.all.info "*/core/iwasm/*" "*/core/shared/*" --output-file coverage.info 2>&1 | tail -3
lcov --summary coverage.info

# Coverage analysis
grep "^FNDA:" coverage.info | grep -v "^FNDA:0," | head -15

# Test code extraction (COMPLETE, not truncated)
awk '/TEST_F\(Suite, Test\)/,/^}$/' file.cc
```

## Example Session Flow

```
INPUT FILE contains:
  /path/smart-tests/aot-1/enhanced_aot_runtime_test.cc  (20 test cases)
  /path/smart-tests/aot-1/enhanced_gen_aot_test.cc      (10 test cases)

Session execution:
1.  PHASE 0: cmake configure (once)

--- File 1: enhanced_aot_runtime_test.cc ---
2.  PHASE 0.5: Run redundancy detection
    ./check_redundant_tests.sh aot-1 smart-tests/aot-1/enhanced_aot_runtime_test.cc
    â†’ Script output: 20 total, 14 useful, 6 redundant
3.  Read /tmp/enhanced_aot_runtime_test_redundant_check.md
    â†’ REDUNDANT: Test2, Test5, Test7, Test8, Test12, Test15
4.  DELETE using script:
    python3 delete_test_cases.py smart-tests/aot-1/enhanced_aot_runtime_test.cc \
        /tmp/enhanced_aot_runtime_test_redundant_check.md
    â†’ âœ… æˆåŠŸåˆ é™¤ 6 ä¸ªæµ‹è¯•ç”¨ä¾‹
5.  CLEANUP: Review file, delete orphaned comments/macros/helpers
6.  Rebuild module: cmake --build build/smart-tests/aot-1
6.  PHASE 1: Create summary file, write cleanup report (6 tests deleted)
7.  PHASE 2: ğŸ“Š Processing Test Case [1/14]: Test1
8.    ... analysis ... append to summary
9.  PHASE 2: ğŸ“Š Processing Test Case [2/14]: Test3
10.   ... analysis ... append to summary
    ... (continue for ALL 14 remaining tests) ...
20. PHASE 2: ğŸ“Š Processing Test Case [14/14]: Test20
21. âœ… PROCESSED_COUNT(14) == TOTAL_COUNT(14) â†’ proceed to PHASE 2.5
22. PHASE 2.5: Generate Path Coverage Summary

--- File 2: enhanced_gen_aot_test.cc ---
23. PHASE 0.5: Run redundancy detection
    ./check_redundant_tests.sh aot-1 smart-tests/aot-1/enhanced_gen_aot_test.cc
    â†’ Script output: 10 total, 8 useful, 2 redundant
24. Read /tmp/enhanced_gen_aot_test_redundant_check.md
25. DELETE using script:
    python3 delete_test_cases.py smart-tests/aot-1/enhanced_gen_aot_test.cc \
        /tmp/enhanced_gen_aot_test_redundant_check.md
26. CLEANUP: Review file, delete orphaned content
27. Rebuild module
27. PHASE 1: Create summary file, write cleanup report (2 tests deleted)
28. PHASE 2: ğŸ“Š Processing Test Case [1/8]: TestA
    ... (continue for ALL 8 remaining tests) ...
35. PHASE 2: ğŸ“Š Processing Test Case [8/8]: TestH
36. âœ… PROCESSED_COUNT(8) == TOTAL_COUNT(8) â†’ proceed to PHASE 2.5
37. PHASE 2.5: Generate Path Coverage Summary
38. FINISH
```
